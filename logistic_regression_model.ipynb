{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef encode_features(data):\n    \"\"\"Adds numerical expressions of categorical variables to the dataset\"\"\"\n    data = data.copy()\n    SEX_MAP = {'Male': 0, 'Female': 1}\n    PCLASS_MAP = {'First class': 1, 'Second class': 2, 'Third class': 3}\n    EMBARKED_MAP = {'S': 0, 'C': 1, 'Q': 2, 'Unknown': -1}\n\n    data['Sex_num'] = data['Sex'].map(SEX_MAP)\n    data['Pclass_num'] = data['Pclass'].map(PCLASS_MAP)\n    data['Embarked_num'] = data['Embarked'].map(EMBARKED_MAP)\n    return data\n\ndef load_and_prepare_data(path):\n    \"\"\"Loads the Titanic dataset, fills missing values, \n    applies formatting and encodes categorical variables.\n    \"\"\"\n    data = pd.read_csv(path)\n\n    #fill missing age by average based on sex and passenger class\n    data['Age'] = data['Age'].fillna(data.groupby(['Sex', 'Pclass'])['Age'].transform('mean'))\n\n    #fill the rest of the missing data\n    data['Cabin'] = data['Cabin'].fillna('Unknown')\n    data['Embarked'] = data['Embarked'].fillna('Unknown')\n    data['Fare'] = data['Fare'].fillna(data.groupby(['Pclass'])['Fare'].transform('mean'))\n   \n    #replace data names to preferred format\n    data['Pclass'] = data['Pclass'].replace({\n        1: 'First class',\n        2: 'Second class',\n        3: 'Third class'\n    })\n\n    data['Sex'] = data['Sex'].replace({\n        'male': 'Male',\n        'female': 'Female'\n    })\n\n    #add numerical expressions of variables to the dataset\n    data = encode_features(data)\n    return data\n\ndef normalize_features(X):\n    return (X - X.min(axis = 0)) / (X.max(axis = 0) - X.min(axis = 0))\n\n#this function is used for logistic regression algorithm\ndef sigmoid(z):\n    \"\"\"Computes the sigmoid activation function used in logistic regression.\"\"\"\n    return 1 / (1 + np.exp(-z))\n\n#computes logistic regression probabilities based on input features and weights\ndef predict(X, weights):\n    \"\"\"Computes predicted probabilities using logistic regression.\"\"\"\n    z = np.dot(X, weights)\n    return sigmoid(z)\n\ndef train_logistic_regression(data):\n    \"\"\"\n    Trains a logistic regression model using gradient descent.\n    Returns prediction and trained weights.\n    \"\"\"\n    features = ['Sex_num', 'Pclass_num', 'SibSp', 'Parch', 'Embarked_num', 'Age', 'Fare']\n    X = data[features].values\n    Y = data['Survived'].values\n\n    X = normalize_features(X)\n\n    repeats = 2000\n    weights = np.zeros(X.shape[1])\n    lr = 0.1\n    for i in range(repeats):\n        prediction = predict(X, weights)\n        error = prediction - Y\n        gradient = np.dot(X.T, error) / len(Y)\n        weights -= lr * gradient\n    return prediction, weights\n\ndef find_best_threshold(data):\n    \"\"\"\n    Finds the optimal threshold for classification based on accuracy.\n    \"\"\"\n    best_accuracy = 0\n    best_threshold = 0\n    for threshold in np.arange(0.3, 0.7, 0.01):\n        predictions = (data['PredictedChance'] >= threshold).astype('int')\n        accuracy = (predictions == data['Survived']).mean()\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_threshold = threshold\n    return best_threshold\n\ndef train_logistic_model(data):\n    \"\"\"Trains the logistic model and returns weights, threshold, and updated data.\"\"\"\n    predictions, weights = train_logistic_regression(data)\n    data['PredictedChance'] = predictions\n    threshold = find_best_threshold(data)\n    return weights, threshold, data\n    \ndef predict_test(data, weights, threshold):\n    \"\"\"Predicts survival on the test set and returns submission-ready DataFrame.\"\"\"\n    features = ['Sex_num', 'Pclass_num', 'SibSp', 'Parch', 'Embarked_num', 'Age', 'Fare']\n    X = data[features].values\n    predictions = predict(X, weights)\n    data['PredictedChance'] = predictions\n    data['Survived'] = (predictions >= threshold).astype('int')\n    return data[['PassengerId', 'Survived']]\n\ndef evaluate_predictions(data, threshold):\n    predictions = (data['PredictedChance'] >= threshold).astype('int')\n    actual = data['Survived']\n    correct = (predictions == actual).sum()\n    total = len(actual)\n    accuracy = correct / total\n    print(f\"Model accuracy: {accuracy: .4f}\")\n\ndef main():\n    train = load_and_prepare_data('/kaggle/input/titanic/train.csv')\n    test = load_and_prepare_data('/kaggle/input/titanic/test.csv')\n\n    weights, threshold, train = train_logistic_model(train)\n    submission = predict_test(test, weights, threshold)\n\n    evaluate_predictions(train, threshold)\n\n    submission.to_csv('submission.csv', index = False)\n\nmain()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-22T21:03:46.733098Z","iopub.execute_input":"2025-07-22T21:03:46.733555Z","iopub.status.idle":"2025-07-22T21:03:46.863978Z","shell.execute_reply.started":"2025-07-22T21:03:46.733503Z","shell.execute_reply":"2025-07-22T21:03:46.863231Z"}},"outputs":[{"name":"stdout","text":"Model accuracy:  0.8182\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}